Vagrant.configure("2") do |config|
    config.vm.box = "ubuntu/jammy64" # Ubuntu 22.04 LTS
    config.vm.provider "virtualbox" do |vb| # We are using Virtual Box on our Windows Machine
        vb.memory = "1024"
        vb.cpus = 1
    end

    # Shared provision for all VMs, where we are updating the package list
    config.vm.provision "shell", inline: <<-SHELL
        echo "Running system update..."
        sudo apt-get update
    SHELL

    # This will be our database VM hosting postgres SQL server
    config.vm.define "db" do |db|
        db.vm.hostname = "db-server" # alwys useful to have a hostname for the VMs
        # This IP adress is the private network IP address that allows communication between VMs
        db.vm.network :private_network, ip:"192.168.61.11" 
        # We are forwarding port 22 of the guest VM to port 2223 on the host machine for SSH access
        # This allows us to SSH into the VM using `ssh -p 2223 vagrant@localhost` from our windows machine.
        # You could also use `vagrant ssh main` to SSH into the VM.
        db.vm.network "forwarded_port", guest: 22, host: 2223, id: "ssh"
    end
    
    # This will be our web VM with the python flask application and nginx server
    config.vm.define "web" do |web|
        web.vm.hostname = "web-server"
        web.vm.network :private_network, ip:"192.168.61.12"
        web.vm.network "forwarded_port", guest: 22, host: 2224, id: "ssh"
        # Now this is interesting, we are forwarding port 80 of the guest VM to port 8080 on the host machine
        # as well as port 5000 for the Flask application
        # Why? Because we want to access the web application running on the VM from our host machine
        web.vm.network "forwarded_port", guest: 80, host: 8080, id: "http"
        web.vm.network "forwarded_port", guest: 5000, host: 5000, id: "flask"
    end

    # And finally is our main VM serving as the Ansible Controller
    # It is configured last, so it can access the other VMs' SSH keys
    config.vm.define "main" do |main|
        main.vm.hostname = "main-server"
        main.vm.network :private_network, ip:"192.168.61.10"
        main.vm.network "forwarded_port", guest: 22, host: 2222, id: "ssh"
        
        # Now since we love automation, we are already installing ansible on our Controller VM
        # and setting up the SSH keys for the other VMs so that Ansible can connect to them.
        # You could also use SSH keygen to generate the keys, but we are using the keys generated by Vagrant
        # ATTENTION: We are using `privileged: false` to run the script as the vagrant user not as the root user.
        # This is important because we want to create the SSH keys in the vagrant user's home directory.
        main.vm.provision "shell", privileged: false, inline: <<-SHELL
            # Create secure directory for SSH keys
            mkdir -p /home/vagrant/.ssh/keys
            chmod 700 /home/vagrant/.ssh/keys
            
            # Copy and secure keys
            cp /vagrant/.vagrant/machines/db/virtualbox/private_key /home/vagrant/.ssh/keys/db_key
            cp /vagrant/.vagrant/machines/web/virtualbox/private_key /home/vagrant/.ssh/keys/web_key
            chmod 600 /home/vagrant/.ssh/keys/*
            
            echo "SSH keys secured and ready for Ansible"

            # Create ansible.cfg in the vagrant user's home directory
            # This configuration file will be used by Ansible automatically and sets useful defaults
            cat > /home/vagrant/.ansible.cfg << EOF
[defaults]
inventory = /vagrant/ansible/inventory.yml
remote_user = vagrant
host_key_checking = False
interpreter_python = /usr/bin/python3
roles_path = /vagrant/ansible/roles

[ssh_connection]
pipelining = True
EOF
            echo "Ansible configuration created in /home/vagrant/.ansible.cfg"
        SHELL
        
        # And now we are installing Ansible in a Python virtual environment via pip
        # This is a good practice to avoid conflicts with system packages and to keep the environment clean
        # Also, ansible versioning is sometimes confusing (at least for me), especially with collections, so we are pinning it to a specific version
        # And we are adding 'activate' command to the .bashrc file so that the venv is activated automatically when the vagrant user logs in
        main.vm.provision "shell", inline: <<-SHELL
            echo "Installing Ansible via pip in venv for vagrant user..."

            apt-get install -y python3-pip python3-venv

            sudo -u vagrant python3 -m venv /home/vagrant/.venv/ansible
            sudo -u vagrant /home/vagrant/.venv/ansible/bin/pip install --upgrade pip
            sudo -u vagrant /home/vagrant/.venv/ansible/bin/pip install ansible==9.5.1

            echo 'export PATH="/home/vagrant/.venv/ansible/bin:$PATH"' >> /home/vagrant/.bashrc
            echo 'source /home/vagrant/.venv/ansible/bin/activate' >> /home/vagrant/.bashrc
            echo "Ansible installed!"
            su - vagrant -c "/home/vagrant/.venv/ansible/bin/ansible --version"
        SHELL

        # For the ansible collections we are using requirements.yml for reproducible collection management
        # As you can see in the yml file, we are also pinning the versions of the collections to avoid breaking changes
        main.vm.provision "shell", privileged: false, inline: <<-SHELL
            echo "Installing Ansible collections from requirements.yml..."
            /home/vagrant/.venv/ansible/bin/ansible-galaxy collection install -r /vagrant/ansible/requirements.yml
            echo "Collections installed"
            /home/vagrant/.venv/ansible/bin/ansible-galaxy collection list
        SHELL
    end

    # Post-up message to inform the user that the VM is ready
    config.vm.post_up_message = "
    The VM is ready!
    "
end